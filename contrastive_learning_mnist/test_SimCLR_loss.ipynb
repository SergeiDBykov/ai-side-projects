{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#torch functional\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.functional as functional\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0429899411238557\n"
     ]
    }
   ],
   "source": [
    "class SimCLRLoss(nn.Module): #TODO check/test this loss\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(SimCLRLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, zis, zjs):\n",
    "        batch_size = zis.size(0)\n",
    "\n",
    "        # Normalize the embeddings\n",
    "        zis = F.normalize(zis, dim=1)\n",
    "        zjs = F.normalize(zjs, dim=1)\n",
    "\n",
    "        # Compute similarity\n",
    "        representations = torch.cat([zis, zjs], dim=0)\n",
    "        similarity_matrix = self.similarity_f(representations.unsqueeze(1), representations.unsqueeze(0))\n",
    "\n",
    "        # Create the labels\n",
    "        labels = torch.cat([torch.arange(batch_size) for i in range(2)], dim=0)\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "\n",
    "        # Mask to remove positive samples from the similarity matrix\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        # Apply temperature\n",
    "        similarity_matrix = similarity_matrix / self.temperature\n",
    "\n",
    "        # Create target labels\n",
    "        target = torch.arange(batch_size).to(device) #used to be .to(labels.device) and it DID not work! no idea why\n",
    "\n",
    "        loss_i = self.criterion(similarity_matrix[:batch_size], target)\n",
    "        loss_j = self.criterion(similarity_matrix[batch_size:], target)\n",
    "\n",
    "        loss = (loss_i + loss_j) / 2\n",
    "        return loss\n",
    "\n",
    "criterion = SimCLRLoss(temperature=0.1)\n",
    "\n",
    "\n",
    "#make random encoded 16 batch size 8\n",
    "batch_size_curr = 8\n",
    "latent_dim = 15\n",
    "\n",
    "encoded_view1 = np.random.rand(batch_size_curr, latent_dim)\n",
    "encoded_view2 = np.random.rand(batch_size_curr, latent_dim)\n",
    "\n",
    "encoded_cat = np.concatenate((encoded_view1, encoded_view2), axis=0)\n",
    "\n",
    "zis = encoded_cat[:batch_size_curr]\n",
    "zjs = encoded_cat[batch_size_curr:]\n",
    "\n",
    "loss_tf = criterion(torch.tensor(zis), torch.tensor(zjs))\n",
    "print(loss_tf.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0429899411238557\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#now calculate loss by hand using numpy\n",
    "\n",
    "# Normalize the embeddings and calculate similarity\n",
    "zis = zis / np.linalg.norm(zis, axis=1)[:, np.newaxis]\n",
    "zjs = zjs / np.linalg.norm(zjs, axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "representations = np.concatenate([zis, zjs], axis=0)\n",
    "similarity_matrix = np.dot(representations, representations.T)\n",
    "\n",
    "#create labels for cross entropy\n",
    "labels = np.concatenate([np.arange(batch_size_curr) for i in range(2)], axis=0)\n",
    "labels = (labels[:, np.newaxis] == labels[np.newaxis, :]).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "mask = np.eye(labels.shape[0], dtype=bool)\n",
    "labels = labels[~mask].reshape(labels.shape[0], -1)\n",
    "similarity_matrix = similarity_matrix[~mask].reshape(similarity_matrix.shape[0], -1)\n",
    "\n",
    "similarity_matrix /= 0.1\n",
    "\n",
    "target = np.arange(batch_size_curr)\n",
    "\n",
    "\n",
    "def cross_entropy(pred, target):\n",
    "    pred = np.exp(pred)\n",
    "    pred /= pred.sum(axis=1)[:, np.newaxis]\n",
    "    return -np.log(pred[np.arange(len(pred)), target]).mean()\n",
    "Àù\n",
    "loss_i = cross_entropy(similarity_matrix[:batch_size_curr], target)\n",
    "\n",
    "loss_j = cross_entropy(similarity_matrix[batch_size_curr:], target)\n",
    "\n",
    "loss = (loss_i + loss_j) / 2\n",
    "\n",
    "print(loss)\n",
    "\n",
    "\n",
    "print(loss_tf.item()/loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
